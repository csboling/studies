\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{enumerate}
\usepackage{hyperref}

\newcommand\dif{\mathop{}\!\mathrm{d}}
\renewcommand{\Im}{\mathrm{Im}}
\renewcommand{\Re}{\mathrm{Re}}
\newcommand{\ord}{\mathrm{ord}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Res}{\mathrm{Res}}
\renewcommand{\Im}{\mathrm{Im}}

\begin{document}

\section{Basic computations with complex numbers}

\subsection{Arithmetic}

\subsection{Triangle Inequality}
Useful inequalities for a metric
$\| x - y \|$ include
\begin{align*}
      \| x + y \|
&\leq \| x \| + \| y \| \\
      \| x - y \|
&\geq \| x \| - \| y \|
\end{align*}
For the complex modulus specifically,
\begin{align*}
      | z |
&\leq \Re~z, \Im~z
\end{align*}

\subsection{Polar and rectangular form}

We have
\begin{align*}
   \frac{r e^{i\theta}}
        {s e^{i\varphi}}
&= \frac{r}{s} e^{i(\theta - \varphi)}, \\
   \frac{x + iy}
        {u + iv}
&= (x + iy)
   \frac{u - iv}
        {u^2 + v^2}
 = \frac{ux - ixv + iyu + yv}
        {u^2 + v^2} \\
&= \frac{(xu + yv) - i(xv + yu)}
        {u^2 + v^2}
\end{align*}
and
\begin{align*}
   r e^{i \theta} + s e^{i \varphi}
&= (r \cos \theta
 +  s \cos \varphi)
 + (ir \sin \theta
 +  is \sin \theta).
\end{align*}
In particular
\begin{align*}
   \frac{1 + i}
        {1 - i}
&= \frac{\sqrt{2} e^{i \frac{\pi}{4}}}
        {\sqrt{2} e^{-i\frac{\pi}{4}}
 = e^{i \frac{\pi}{2}} = i \\
&= h_i(1),
\end{align*}
whereas $h_i(i) = \infty$, $h_i(0) = -1$.

\subsection{Powers and $n$-th roots (polar form)}
A complex number
$$
z = r e^{i (\theta + 2 \pi k)}
$$
has $n$-th roots
$$
  z^{\frac{1}{n}}
= \sqrt[n]{r} e^{\frac{\theta}{n} + 2 \pi \frac{k}{n}}
$$
and $n$-th power
$$
  z^n
= r^n (\cos n\theta + i \sin n\theta).
$$
Note that
$$
\frac{\theta + 2 \pi k}{n} = 2 \pi m
$$
when
$$
\theta = 2 \pi (mn - k)
$$
for some $k, m \in \mathbb{Z}$.
We can also write
$$
  z^{\frac{1}{n}}
= e^{\frac{1}{n} \log z}
$$
so that this function is dependent on a choice of branch cut
of $\log z$.

\subsection{Complex exponential, logarithm,
                  trigonometric and hyperbolic functions}

We can define
\begin{align*}
   \cosh z
&= \frac{e^z + e^{-z}}{2}
 = \frac{e^{-i(iz)} + e^{i(iz)}}{2} \\
&= \cos iz, \\
   \sinh z
&= \frac{e^z - e^{-z}}{2}
 = \frac{e^{-i(iz)} - e^{i(iz)}}{2} \\
&= -i \sin iz.
\end{align*}
Useful identities:
\begin{align*}
   \sin (x + i y)
&= \sin x \cosh y
 + i \cos x \sinh y, \\
   \cos (x + i y)
&= \cos x \cosh y
 - i \sin x \sinh y
\end{align*}

\section{Topology on $\mathbb{C}$}

The topology on $\mathbb{C}$ is generated by open disks.
A closed set $\bar{U}$ is the complement of an open set
and satisfies
\begin{enumerate}
  \item{
    that it contains its boundary and contains all its
    limit points, i.e. it is closed under the limit operation
  }
  \item{
    that every bounded sequence in $\bar{U}$ contains a
    convergent subsequence
  }
\end{enumerate}

A subset $A \subset U$ is said to be relatively open in $U$ if
for each $z_0 \in A$, there exists an $r$ such that
$D(z_0, r) \cap U$ lies in $U$. Informally, each point in $A$ has an
open neighborhood also in $A$, which may be truncated by the boundary
of $U$.
A subset $A \subset U$ is said to be relatively closed in $U$
if $U - A$ is relatively open in $U$.
If a set is open and connected, it is path-connected.

Continuous functions on compact sets are uniformly continuous and have
compact images. The uniform limit of continuous functions is continuous.

\section{Complex differentiability, Cauchy-Riemann equations}

Let $U \subset \mathbb{C}$ be open. We say that $f$ is
holomorphic on $U$ if, for each $z_0 \in U$, the limit
$$
  \lim_{z \to z_0}
    \frac{f(z) - f(z_0)}
         {z - z_0}
$$
exists. This is equivalent to total differentiability of
$f(x + i y) = u(x, y) + i v(x, y)$, which is satisfied if and
only if
$$
  \left[
    \begin{array}{r r}
       \frac{\partial}{\partial x}
    & -\frac{\partial}{\partial y} \\
       \frac{\partial}{\partial x}
    &  \frac{\partial}{\partial y}
    \end{array}
  \right]
  \left[
    \begin{array}{c}
      u \\
      v
    \end{array}
  \right]
= \mathbf{0}.
$$

We can also write
$$
f^\prime = u_x + i v_x = v_y - i u_y.
$$

\subsection{Branches of the logarithm (primitive of $\frac{1}{z}$),
                  complex powers}

A branch of the logarithm in an open set
$U \subset \mathbb{C} \setminus \{ 0 \}$ is defined to be
a continuous function $L$ that satisfies
$\exp \circ L = \mathrm{id}$ on $U$.

A branch of the logarithm with $\theta \in (0, 2 \pi)$ is
given by
$$
  \log z
= \log |z| + i \arg z, \quad
  \arg z \in (0, 2 \pi)
$$
but we may also choose a branch cut along any half-line
$$
  t e^{i \theta_0}, \quad
  t \in [0, \infty),
$$
in which case
$$
  \log z
= \log |z| + i \arg z, \quad
  \theta_0 < \arg z < \theta_0 + 2 \pi.
$$

\subsubsection{Properties of the logarithm}
Any function that is a primitive of $\frac{1}{z}$ on $U$
differs from a branch of the logarithm by an additive
constant. We may define a branch of the logarithm on
any simply connected domain that excludes 0.

More generally, given a
$f: U \to \mathbb{C} \setminus \{ 0 \}$,
holomorphic on an open set $U$
we can find a function $L$ that satisfies
$\exp \circ L \circ f = f$ and
$$
  \frac{\dif}{\dif z}
  (L \circ f)(z)
= L^\prime(f(z)) \cdot f^\prime(z)
= \frac{f^\prime(z)}
       {f(z)}
$$
on $U$, and we say that $\log f$ is a primitive of
$\frac{f^\prime}{f}$.

A logarithm on an arbitrary subset of
$\mathbb{C} \setminus \{ 0 \}$ can be found by
$$
  L(z)
= \log z_0 + \int_\gamma \frac{1}{w} \dif w
$$
where $\gamma(0) = z_0$ and $\log z_0$ is taken over a chosen
branch.

\subsection{Uniqueness theorem for holomorphic functions}

If two functions $f$, $g$ are holomorphic on an open set
$U$, and equal on a subset $S \subset U$ which has an
accumulation point in $U$, then $f = g$ on $U$. This is a
consequence of the fact that zeros of a holomorphic function
must be isolated, which can be seen by a power series
argument.

\section{Power Series}

The radius of convergence of the sum of two convergent power series is
the minimum of their individual radii of convergence. The radius of
convergence of the product is at least the minimum.

\subsection{Useful formulas}
Finite geometric progression sum:
$$
  \sum_{k=0}^n z^k
= \frac{z^{n+1}} - 1}
       {z - 1}.
$$

Rewriting a double sum involving a finite convolution:
$$
  \sum_{n=0}^\infty
  \sum_{k=0}^n
    a_{k,n-k}
= \sum_{m=0}^\infty
  \sum_{n=0}^\infty
    a_{n,m}
$$

Binomial theorem:
$$
  (a + b)^n
= \sum_{k=0}^n
    {n \choose k}
    a^k
    b^{n-k}
$$

Expanding a difference of powers:
$$
  (a - b)^n
= (a - b)
  \sum_{k=0}^{n-1}
    a^{n - k - 1} b^k
$$

\subsection{Comparison tests}
If $|a_n| \leq c_n$ for a real nonnegative
sequence $c_n$ and $\sum c_n$ converges, then
$\sum a_n$ converges absolutely.

If $\| f_n \|_U \leq c_n$ for some nonnegative real sequence
$c_n$ and $\sum c_n$ converges, then $\sum f_n$
converges uniformly and absolutely on $U$.

If for a fixed $r > 0$, $\sum |a_n| r^n$ converges, then
$\sum a_n z^n$ converges absolutely and uniformly for
$|z| \leq r$.

\subsection{Radius of convergence}
Define $\limsup a_n$ to be the supremum of the set of accumulation
points of the sequence $(a_n)$.
When $t = \limsup |a_n|^{1 / n}$,
$|a_n| \leq (t + \varepsilon)^n$ for cofinitely many $n$
for every $\varepsilon > 0$. Then
when $|z| < \frac{1}{t + \varepsilon}$,
$|a_n| |z|^n < 1$, so $\sum a_n z^n$ converges absolutely.

From real analysis,
$ \lim \frac{|a_{n+1}|}{|a_n|}
= \lim |a_n|^{1 / n}
= \limsup |a_n|^{1 / n}$ if the first two limits exist.

\subsection{Derivative of power series}

\subsection{Difference equations}

\subsection{Coefficient expressions using derivatives}
Since $f(z_0) = a_0$, $f^{(n)}(z_0) = n! a_n$, etc.
we have the usual Taylor expansion for an analytic function.


\section{Integration on curves}

\subsection{Using definitions, using primitives}
By definition,
$$
  \int_\gamma
    f(z)
    \dif z
= \int_a^b
    f(\gamma(t)) \cdot \gamma^\prime(t)
    \dif t,
$$
and
$$
  g(\gamma(b)) - g(\gamma(a))
= \int_\gamma
    f(z) \dif z
$$
if (and only if) $g^\prime = f$. Notably, the function $(z - z_0)^n$ has the
primitive $\frac{(z - z_0)^{n+1}}{n + 1}$ for $n \neq -1$, so a Laurent series
at a point $z_0$ with finitely many negative terms can be integrated
term-by-term around a closed curve to give $\int_\gamma f = 2 \pi i a_{-1}$.


\section{Cauchy's theorem and formula}

Path-independence of integrals, existence of a primitive,
and zero integral around closed paths are equivalent.

Cauchy's theorem for Jordan curves says that for a Jordan
curve $\gamma$ and a function $f$ holomorphic on
$\gamma \cup \mathrm{Int}(\gamma)$,
$$
  \oint_\gamma
    f(z)
    \dif z
= 0.
$$

By expanding $g(w) = \frac{f(z)}{z - w}$ in a geometric series in $(w
- w_0)$, we can see
$$
  f(w)
= \frac{1}{2 \pi i}
  \int_J
    \sum_{n=0}^\infty
      \frac{f(z)}{(z - w_0)^{n+1}}
      (w - w_0)^n
$$
and after showing that this series converges uniformly it follows that
$$
  f^{(k)}(w)
= \frac{n!}{2 \pi i}
  \int_J
    \frac{f(z)}
         {(z - w)^{n+1}}, \quad w \in \mathrm{Int}(J).
$$

The radius of a power series expansion at $z_0$ of a holomorphic function on a
domain $U$ is at least $\mathrm{dist}(z_0, \mathbb{C} \setminus U)$.

\subsection{Liouville's theorem, fundamental theorem of algebra}

Any bounded entire function is constant. If a polynomial $P$ has no
zero, then $\frac{1}{P}$ is entire, and
$\lim_{z \to \infty} \frac{1}{P} = 0$ so $\frac{1}{P}$ is bounded on
$\mathbb{C} \setminus \bar{D}(0, R)$ for some $R$. Since
$\left(\frac{1}{P}\right)(\bar{D}(0, R))$ is compact we can conclude
that $\frac{1}{P}$ is bounded, thus constant, so $P$ is constant.

\subsection{Simply connected domains}
We say that a domain $U$ (i.e. an open connected subset of $\mathbb{C}$)
is simply connected if the interior of every Jordan curve in $U$ lies
in $U$. Equivalently, every closed curve in $U$ is homotopic to a point.
Note that a star domain is simply connected.

\subsubsection{Existence of primitives}
A function is holomorphic on a simply connected domain if and only if
it has a primitive on that domain.
On a simply connected open set,
$g(z) = \int_{z_0}^z f(\zeta) \dif \zeta$ is a primitive for $f$,
where $z_0$ is any point in the set.

\subsubsection{Branch of $\log z$}
If $U \subset \mathbb{C} \setminus \{ 0 \}$ is simply connected then
$\frac{1}{z}$ has a primitive, which differs from a branch of the
logarithm by an additive constant. If $\frac{f^\prime}{f}$ has a
primitive in $U$, then it differs from a branch of $\log f$ by a
constant, i.e. a continuous function $L$ such that
$\exp \circ L = f$.

\subsubsection{Harmonic conjugates}
Given a harmonic function $u$, $f = u_x - i u_y$ is holomorphic, and so if
the domain of definition is simply connected then $f$ has a primitive
$F$ there. $\Re~F$ shares both its derivatives
with $u$ and thus differs from $u$ by a real constant $C$, so
$\Im(F - C)$ is a harmonic conjugate for $u$.

To find the harmonic conjugate explicitly, we solve the
Cauchy-Riemann equations $v_y = u_x$ and $v_x = -u_y$. The first gives
$v = k(x, y) + h(x)$, the second then gives
$-u_y = k^\prime(x, y) + h^\prime(x)$, and if $u$ is harmonic it is
possible to solve this for $h$.

\subsubsection{Riemann Mapping Theorem}



\section{Harmonic functions}
A harmonic function $f$ is one that satisfies
$$
  \nabla^2 f
= \sum_i
    \frac{\partial^2 f}
         {\partial x_i^2}
= 0,
$$
which is satisfied for holomorphic functions by the Cauchy-Riemann
equations. A function $f$ is harmonic on an open set $U$
if and only if $f_x - i f_y$ is holomorphic on $U$.

\subsection{Mean value theorems}
If $f$ is harmonic (and thus also if $f$ is holomorphic) then
$$
  f(z_0)
= \frac{1}{2\pi}
  \int_{0}^{2\pi}
    f(z_0 + re^{i\theta})
    d \theta
= \frac{1}{\pi r^2}
  \int_{D(z_0, r)}
    f(z) \dif x \dif y
$$

\subsection{Maximum principle}



\section{Residue calculus}

\subsection{Winding number}
The winding number is defined by
$$
  W(\gamma; z_0)
= \frac{1}{2 \pi i}
  \int_\gamma
    \frac{1}{z - z_0}
    \dif z.
$$
The winding number of a curve at a point outside the curve is
0. Crossing the curve from the right to the left increases the winding
number by 1.

\subsection{General Cauchy's formula}
Let $\gamma$ be a closed contour. Then
$$
  2 \pi i W(\gamma; z_0) \cdot f^{(k)}(z_0)
= \int_\gamma
    \frac{f(z)}{(z - z_0)^{k+1}}
    \dif z
$$

\subsection{Laurent series}

The coefficients of a Laurent series on the annulus $A(z_0, r, R)$
are given by
$$
  a_n
= \frac{1}{2 \pi i}
  \int_{|z - z_0| = t}
    \frac{f(z)}{(z - z_0)^{n+1}},
n \in \mathbb{Z},
t \in (r, R)
$$

\subsubsection{Product and ratio}
We can compute
$$
  \left(
    \sum_{n=0}^\infty
      a_n
      (z - z_0)^n
  \right)
  \left(
    \sum_{n=0}^\infty
      b_n
      (z - z_0)^n
  \right)
= \sum_{n=0}^\infty
    \left(
      \sum_{k=0}^n
        a_k
        b_{n-k}
    \right)
    (z - z_0)^n
$$
and can use this to recursively solve $\frac{f}{g} \cdot g = f$ for
$\frac{f}{g}$. The first few terms may also be computed by polynomial
long division.

\subsection{Residue formula}
Let $z_i$ be the poles of $f$, which is holomorphic on
Jordan curve $J$ and its interior except for
at these points. Then
$$
  \int_J f
= 2 \pi i
  \sum_i
  \Res_{z_0}~f.
$$
This implies Cauchy's theorem since the sum is empty for a holomorphic
function as well as Cauchy's formula since
$$
  \frac{1}{2 \pi i}
  \int_\gamma
    \frac{f(z)}
         {(z - z_0)^{n+1}}
    \dif z
= \Res_{z_0}
    \frac{f(z)}{(z - z_0)^{n+1}}
= f^{(n)}(z_0).
$$

\section{Singularities}

\subsection{Classification}

\begin{enumerate}
  \item{
    A singularity $z_0$ of $f$ is said to be removable if the Laurent
    expansion about $z_0$ has no negative terms. In this case, the
    function
    $$
      g(z)
    = \left\{
        \begin{array}{l l}
          f(z), & \quad z \neq z_0 \\
          a_0,  & \quad z = z_0
        \end{array}
    $$
    where $a_0$ is the 0 coefficient of the Laurent series. This is
    because the limit of $f$ exists at $z_0$.

    Sufficiently near a removable singularity, $f$ is bounded,
    explicitly by $|\lim_{z \to z_0} f| + \varepsilon$ for any
    $\varepsilon > 0$, for $z \in D(z_0, r(\varepsilon))$.
  }
  \item{
    A singularity $z_0$ of $f$ is said to be a pole of order $m$ if
    $a_{-m} \neq 0$ and $a_{-n} = 0$ for $n > m$. In this case
    $$
      f(z)
    = \frac{g(z)}
           {(z - z_0)^m}
    $$
    where $g$ is holomorphic.

    In this case $\lim_{z \to z_0} |f| = \infty$. Therefore
    $\lim_{z \to z_0} \left|\frac{1}{f}\right| = 0$, so $z_0$ is a
    removable singularity of $\frac{1}{f}$.
  }
  \item{
    A singularity $z_0$ of $f$ is said to be essential if it is not
    removable or a pole.

    In this case
    $f(D(z_0, r)) = \mathbb{C}$ or $\mathbb{C} \setminus \{ w_0 \}$
    (for some $w_0$) for any $r > 0$. In some ways essential
    singularities behave like poles of infinite order.
  }
\end{enumerate}

\subsection{Finding Laurent series of $\frac{1}{z - z_0}$}
Let
$$
  f(z)
= \frac{1}{z - z_0}
$$
This function is already its own
Laurent series around $z_0$.

When $z_0 \neq 0$, and $\left| \frac{z}{z_0} \right| < 1$,
we have
\begin{align*}
   -\frac{1}{z_0} f(z)
&=  \frac{\frac{1}{z_0}}
         {1 - \frac{z}{z_0}}
 = -\frac{1}{z_0}
    \sum_{n=0}^\infty
      \left(\frac{z}{z_0}\right)^n
\end{align*}
which is a Laurent series around 0.

\subsection{Computing residues}

If $g$, $f$ are holomorphic and
$h = \frac{g}{f}$, and $\ord_{z_0} f = 1$, then
$\Res_{z_0} h = \frac{g(z_0)}{f^\prime(z_0)}$.

A useful manipulation for results like this is to express
a function as $\frac{1}{z - z_0} h(z)$ or
$\frac{C}{z - z_0} + h(z)$ for some holomorphic function
$h(z)$. In the latter case the residue is of course $C$, and in the
former case it is $a_0$, where $a_0 = h(z_0)$ is the first term of the
Taylor series of the function $h$ which is analytic at $z_0$. More
generally the idea is to ``displace'' a holomorphic function by some
number of powers of $(z - z_0)$ to compute the residue more easily;
this is analogous to the computation of say
$$
  \Res_0 \frac{\sin z}{z^6}
= \frac{\sin^{(5)}(0)}{5!}.
$$
Another useful example of this approach is the observation that when
$f(z) = (z - z_0)^m g(z)$,
$$
  \Res_{z_0} \frac{f^\prime}{f}
= \Res_{z_0}
  \left\{
    \frac{m}{z - z_0} + \frac{g^\prime(z)}{g(z)}
  \right\}
= \ord_{z_0} f
$$
from which it follows that
$$
  \frac{1}{2 \pi i}
  \int_\gamma f
= \mathrm{Zeros}_{\mathrm{Int}(\gamma)}(f)
- \mathrm{Poles}_{\mathrm{Int}(\gamma)}(f).
$$

\subsection{Rouch\'e's theorem}
If $|f(z) - g(z)| < |f(z)|$ on the boundary of a disk
$D$ and $f$, $g$ are analytic on the closed disk, then they have the
same number of zeros within the disk.

If a zero $z_0$ of $P(z)$ is not a simple zero, then it is also a zero
of $P^\prime(z)$. We can compute $Q = \mathrm{gcd}(P, P^\prime)$ by
polynomial long division, and the roots of $Q$ are the multiple roots
of $P$.

\subsection{Open mapping theorem, inverse mapping theorem}
If a holomorphic function is non-constant on every open disk in its
domain, then it is an open mapping. Similarly, if $f^\prime(z_0) \neq
0$, $f$ is locally non-constant and indeed injective, since in this
case $\ord_{z_0} (f - f(z_0)) = 1$ and there is an
$r$ such that for any $w \in D(f(z_0), r)$, $f - w$ has the same
number of zeros as $f - f(z_0)$.

More generally, if $m = \ord_{z_0} (f - f(z_0)) \in \mathbb{N}$, then
$$
f(z) = (\sqrt[m]{a_m} (z - z_0)(1 + h(z)))^m = f_0(z)^m
$$
on some disk $D(z_0, r)$, where $h(z_0) = 0$ and so $f_0^\prime(z_0)
\neq 0$, whence $f_0$ is not constant anywhere on this disk. Therefore
$f_0$ is open, and the image of a disk under the power map is a disk.

If $|f(z_0)|$ is a local maximum for $|f|$, then $f$ is locally
constant at $z_0$. Indeed if $f$ is not locally constant, then
$f(D(z_0, r))$ is open, so $D(f(z_0), s) \subset f(D(z_0, r))$, so
$|f(z_1)| = |f(z_0)| + s > |f(z_0)|$ for some $z_1 \in D(z_0, r)$.

If $f^\prime(z_0) = 0$, then $f^\prime$ is either locally constant or
$z_0$ is an isolated zero of $f^\prime$: it is not true in this case
that $f$ is locally constant, consider $f(z) = z^2 - 1$ at zero.


\section{Contour integration}

\subsection{Half-disk}

\subsection{Half-disk minus half-disk}

\subsection{Taking real parts}

\subsection{Rectangular contours}

\subsection{Trigonometric integrands}

\subsection{Integrals involving branch cuts}


\section{Conformal maps}

\subsection{Automorphisms}
The automorphisms of the disk are all of the form $M_c \circ g_\alpha$ where
$$
  g_\alpha(z)
= \frac{\alpha - z}
       {1 - \bar{\alpha} z}.
$$
The automorphisms of the upper half-plane are all of the form
$h_{z_2}^{-1} \circ M_c \circ h_{z_1}$, where $z_1, z_2 \in
\mathbb{H}$ and
$$
  h_{z_0}(z)
= \frac{z - z_0}
       {z - \bar{z_0}}
\in \mathrm{Iso}(\mathbb{H}, \mathbb{D}).
$$

\subsection{The Schwarz lemma}
Let $f : \mathbb{D} \to \mathbb{D}$ be holomorphic and $f(0) =
0$. Then $|f^\prime(z)| \leq |z|$ and $|f^\prime(0)| \leq 1$, and if
$|f^\prime(z_0)| = |z_0|$ for any $z_0 \in \mathbb{D}$ or
$|f^\prime(0)| = 1$ then $f$ is a rotation. Furthermore if
$f$ has a nonzero fixed point or $f^\prime(0) = 1$
then $f$ is identity. As a consequence of this, any automorphism of
the unit disk that fixes zero is a rotation.

\section{M\"obius transformations}
A M\"obius transformation can be decomposed as
$$
f = T_{\frac{a}{c}} \circ J \circ T_{\frac{d}{b^\prime}} \circ M_{\frac{c}{b^\prime}}
$$
where $b^\prime = b - \frac{ad}{c}$.

\subsection{Finding the transformation between given circles}
The transformation $F$ mapping $z_1, z_2, z_3$ to $w_1, w_2, w_3$ can be
found by setting $a = 1$ and solving the system of equations $F(z_i) =
w_i$ or by computing
$F = F_{w_1, w_2, w_3}^{-1} \circ F_{z_1, z_2, z_3}$,
where $F_{a, b, c}$ maps $a$ to $0$, $b$ to $\infty$ and $c$ to 1,
explicitly
$$
  F_{a, b, c}
= \frac{c - b}
       {c - a}
  \frac{z - a}
       {z - b},
$$
and so maps the circle defined by these three points onto the real
line. If any $a, b, c$ is $\infty$, we omit the terms containing it.

recognizing that
$$
  [F(z_1), F(z_2), F(z_3), F(z_4)]
= F_{w_2, w_1, w_3}(w_4)
= [z_1, z_2, z_3, z_4]
= F_{z_2, z_1, z_3}(z_4)
$$
so that
$$
w_4 = (F_{w_2, w_1, w_3}^{-1} \circ F_{z_2, z_1, z_3})(z_4)
$$

\subsection{Cross ratio}
The cross-ratio is given by
$$
  [z_1, z_2, z_3, z_4]
= \frac{z_1 - z_3}
       {z_2 - z_3}
  \frac{z_2 - z_4}
       {z_1 - z_4}
= F_{z_2, z_1, z_3}(z_4).
$$


\section{Riemann mapping theorem}
Every nonempty open simply connected subset of $\mathbb{C}$ has a
unique (up to a rotation) isomorphism to the unit disk such that
$f(z_0) = 0$.

\subsection{Compact convergence}
A sequence is said to converge compactly on an open set $U$ if it
converges uniformly on compact subsets of $U$. The limit of a
compactly convergent sequence of holomorphic functions is holomorphic,
which allows us to define new holomorphic functions by showing that a
given series or integral converges compactly (typically by comparison)
and that the partial sums are holomorphic.

\subsection{Normal families}
A collection of analytic functions $\Phi$ is called a normal family if every
sequence in $\Phi$ contains a compactly convergent subsequence.
$\Phi$ is a normal family if and only if $\Phi$ is uniformly bounded
on compact sets (Montel's theorem). If a sequence $(f_n)$ of analytic
functions or its derivative sequence is uniformly bounded on an open
set $U$, then $(f_n)$ is equicontinuous on each compact subset of $U$,
and hence contains a subsequence which converges uniformly on $K$
(Arzel\`a-Ascoli theorem).

\subsection{Finding biholomorphisms}

\section{Miscellaneous}
If a holomorphic function maps real values to real values, then
$f(\bar{z}) = \overline{f(z)}$ on its whole domain.

If $f$ is entire and $\| f \|_{|z| = R} = O(R^k)$, then $f$ is a
polynomial of degree at most $k$.

\end{document}
