\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{enumerate}
\usepackage{hyperref}

\newcommand\dif{\mathop{}\!\mathrm{d}}
\renewcommand{\Im}{\mathrm{Im}}
\renewcommand{\Re}{\mathrm{Re}}
\newcommand{\ord}{\mathrm{ord}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Res}{\mathrm{Res}}
\renewcommand{\Im}{\mathrm{Im}}

\begin{document}

\section{Basic computations with complex numbers}

\subsection{Arithmetic}

\subsection{Triangle Inequality}
Useful inequalities for a metric
$\| x - y \|$ include
\begin{align*}
      \| x + y \|
&\leq \| x \| + \| y \| \\
      \| x - y \|
&\geq \| x \| - \| y \|
\end{align*}
For the complex modulus specifically,
\begin{align*}
      | z |
&\leq \Re~z, \Im~z
\end{align*}

\subsection{Polar and rectangular form}

We have
\begin{align*}
   \frac{r e^{i\theta}}
        {s e^{i\varphi}}
&= \frac{r}{s} e^{i(\theta - \varphi)}, \\
   \frac{x + iy}
        {u + iv}
&= (x + iy)
   \frac{u - iv}
        {u^2 + v^2}
 = \frac{ux - ixv + iyu + yv}
        {u^2 + v^2} \\
&= \frac{(xu + yv) - i(xv + yu)}
        {u^2 + v^2}
\end{align*}
and
\begin{align*}
   r e^{i \theta} + s e^{i \varphi}
&= (r \cos \theta
 +  s \cos \varphi)
 + (ir \sin \theta
 +  is \sin \theta).
\end{align*}
In particular
\begin{align*}
   \frac{1 + i}
        {1 - i}
&= \frac{\sqrt{2} e^{i \frac{\pi}{4}}}
        {\sqrt{2} e^{-i\frac{\pi}{4}}
 = e^{i \frac{\pi}{2}} = i \\
&= h_i(1),
\end{align*}
whereas $h_i(i) = \infty$, $h_i(0) = -1$.

\subsection{Powers and $n$-th roots (polar form)}
A complex number
$$
z = r e^{i (\theta + 2 \pi k)}
$$
has $n$-th roots
$$
  z^{\frac{1}{n}}
= \sqrt[n]{r} e^{\frac{\theta}{n} + 2 \pi \frac{k}{n}}
$$
and $n$-th power
$$
  z^n
= r^n (\cos n\theta + i \sin n\theta).
$$
Note that
$$
\frac{\theta + 2 \pi k}{n} = 2 \pi m
$$
when
$$
\theta = 2 \pi (mn - k)
$$
for some $k, m \in \mathbb{Z}$.
We can also write
$$
  z^{\frac{1}{n}}
= e^{\frac{1}{n} \log z}
$$
so that this function is dependent on a choice of branch cut
of $\log z$.

\subsection{Complex exponential, logarithm,
                  trigonometric and hyperbolic functions}

We can define
\begin{align*}
   \cosh z
&= \frac{e^z + e^{-z}}{2}
 = \frac{e^{-i(iz)} + e^{i(iz)}}{2} \\
&= \cos iz, \\
   \sinh z
&= \frac{e^z - e^{-z}}{2}
 = \frac{e^{-i(iz)} - e^{i(iz)}}{2} \\
&= -i \sin iz.
\end{align*}

\section{Topology on $\mathbb{C}$}

The topology on $\mathbb{C}$ is generated by open disks.
A closed set $\bar{U}$ is the complement of an open set
and satisfies
\begin{enumerate}
  \item{
    that it contains its boundary and contains all its
    limit points, i.e. it is closed under the limit operation
  }
  \item{
    that every bounded sequence in $\bar{U}$ contains a
    convergent subsequence
  }
\end{enumerate}

A subset $A \subset U$ is said to be relatively open in $U$ if
for each $z_0 \in A$, there exists an $r$ such that
$D(z_0, r) \cap U$ lies in $U$. Informally, each point in $A$ has an
open neighborhood also in $A$, which may be truncated by the boundary
of $U$.
A subset $A \subset U$ is said to be relatively closed in $U$
if $U - A$ is relatively open in $U$.

\section{Complex differentiability, Cauchy-Riemann equations}

Let $U \subset \mathbb{C}$ be open. We say that $f$ is
holomorphic on $U$ if, for each $z_0 \in U$, the limit
$$
  \lim_{z \to z_0}
    \frac{f(z) - f(z_0)}
         {z - z_0}
$$
exists. This is equivalent to total differentiability of
$f(x + i y) = u(x, y) + i v(x, y)$, which is satisfied if and
only if
$$
  \left[
    \begin{array}{r r}
       \frac{\partial}{\partial x}
    & -\frac{\partial}{\partial y} \\
       \frac{\partial}{\partial x}
    &  \frac{\partial}{\partial y}
    \end{array}
  \right]
  \left[
    \begin{array}{c}
      u \\
      v
    \end{array}
  \right]
= \mathbf{0}.
$$

\subsection{Branches of the logarithm (primitive of $\frac{1}{z}$),
                  complex powers}

A branch of the logarithm in an open set
$U \subset \mathbb{C} \setminus \{ 0 \}$ is defined to be
a continuous function $L$ that satisfies
$\exp \circ L = \mathrm{id}$ on $U$.

A branch of the logarithm with $\theta \in (0, 2 \pi)$ is
given by
$$
  \log z
= \log |z| + i \arg z, \quad
  \arg z \in (0, 2 \pi)
$$
but we may also choose a branch cut along any half-line
$$
  t e^{i \theta_0}, \quad
  t \in [0, \infty),
$$
in which case
$$
  \log z
= \log |z| + i \arg z, \quad
  \theta_0 < \arg z < \theta_0 + 2 \pi.
$$

\subsubsection{Properties of the logarithm}
Any function that is a primitive of $\frac{1}{z}$ on $U$
differs from a branch of the logarithm by an additive
constant. We may define a branch of the logarithm on
any simply connected domain that excludes 0.

More generally, given a
$f: U \to \mathbb{C} \setminus \{ 0 \}$,
holomorphic on an open set $U$
we can find a function $L$ that satisfies
$\exp \circ L \circ f = f$ and
$$
  \frac{\dif}{\dif z}
  (L \circ f)(z)
= L^\prime(f(z)) \cdot f^\prime(z)
= \frac{f^\prime(z)}
       {f(z)}
$$
on $U$, and we say that $\log f$ is a primitive of
$\frac{f^\prime}{f}$.

A logarithm on an arbitrary subset of
$\mathbb{C} \setminus \{ 0 \}$ can be found by
$$
  L(z)
= \log z_0 + \int_\gamma \frac{1}{w} \dif w
$$
where $\gamma(0) = z_0$ and $\log z_0$ is taken over a chosen
branch.

\subsection{Uniqueness theorem for holomorphic functions}

If two functions $f$, $g$ are holomorphic on an open set
$U$, and equal on a subset $S \subset U$ which has an
accumulation point in $U$, then $f = g$ on $U$. This is a
consequence of the fact that zeros of a holomorphic function
must be isolated, which can be seen by a power series
argument.


\section{Power Series}

\subsection{Useful formulas}
Finite geometric progression sum:
$$
  \sum_{k=0}^n z^k
= \frac{z^{n+1}} - 1}
       {z - 1}.
$$

Rewriting a double sum involving a finite convolution:
$$
  \sum_{n=0}^\infty
  \sum_{k=0}^n
    a_{k,n-k}
= \sum_{m=0}^\infty
  \sum_{n=0}^\infty
    a_{n,m}
$$

Binomial theorem:
$$
  (a + b)^n
= \sum_{k=0}^n
    {n \choose k}
    a^k
    b^{n-k}
$$

Expanding a difference of powers:
$$
  (a - b)^n
= (a - b)
  \sum_{k=0}^{n-1}
    a^{n - k - 1} b^k
$$

\subsection{Comparison tests}
If $|a_n| \leq c_n$ for a real nonnegative
sequence $c_n$ and $\sum c_n$ converges, then
$\sum a_n$ converges absolutely.

If $\| f_n \|_U \leq c_n$ for some nonnegative real sequence
$c_n$ and $\sum c_n$ converges, then $\sum f_n$
converges uniformly and absolutely on $U$.

If for a fixed $r > 0$, $\sum |a_n| r^n$ converges, then
$\sum a_n z^n$ converges absolutely and uniformly for
$|z| \leq r$.

\subsection{Radius of convergence}
Define $\limsup a_n$ to be the supremum of the set of accumulation
points of the sequence $(a_n)$.
When $t = \limsup |a_n|^{1 / n}$,
$|a_n| \leq (t + \varepsilon)^n$ for cofinitely many $n$
for every $\varepsilon > 0$. Then
when $|z| < \frac{1}{t + \varepsilon}$,
$|a_n| |z|^n < 1$, so $\sum a_n z^n$ converges absolutely.

From real analysis,
$ \lim \frac{|a_{n+1}|}{|a_n|}
= \lim |a_n|^{1 / n}
= \limsup |a_n|^{1 / n}$ if the first two limits exist.

\subsection{Derivative of power series}

\subsection{Difference equations}

\subsection{Coefficient expressions using derivatives}
Since $f(z_0) = a_0$, $f^{(n)}(z_0) = n! a_n$, etc.
we have the usual Taylor expansion for an analytic function.


\section{Integration on curves}

\subsection{Using definitions, using primitives}
By definition,
$$
  \int_\gamma
    f(z)
    \dif z
= \int_a^b
    f(\gamma(t)) \cdot \gamma^\prime(t)
    \dif t
$$
and
$$
  g(\gamma(b)) - g(\gamma(a))
= \int_\gamma
    f(z) \dif z
$$
if (and only if) $g^\prime = f$.


\section{Cauchy's theorem and formula}

Path-independence of integrals, existence of a primitive,
and zero integral around closed paths are equivalent.

Cauchy's theorem for Jordan curves says that for a Jordan
curve $\gamma$ and a function $f$ holomorphic on
$\gamma \cup \mathrm{Int}(\gamma)$,
$$
  \oint_\gamma
    f(z)
    \dif z
= 0.
$$

On a disk $D(z_0, r) \subset U$, we can write
\begin{align*}
   \frac{f(z)}
        {z - z_0}
&= \frac{f(z) -
\end{align*}
so that
$$
  f(z)
- \sum_{n=1}^\infty
    a_n (z - z_0)^n
= a_0
$$

\subsection{Liouville's theorem, fundamental theorem of algebra}

\subsection{Simply connected domains}
  \subsubsection{Existence of primitives}
  \subsubsection{Branch of $\log z$}
  \subsubsection{Harmonic conjugates}
  \subsubsection{Riemann Mapping Theorem}



\section{Harmonic functions}

\subsection{Mean value theorems}

\subsection{Maximum principle}



\section{Residue calculus}

\subsection{Winding number}

\subsection{General Cauchy's formula}

\subsection{Laurent series}

\subsubsection{Product and ratio}

\subsection{Residue formula}
  Implies Cauchy's theorem and Cauchy's formula



\section{Singularities}

\subsection{Classification}

\begin{enumerate}
  \item{
    A singularity $z_0$ of $f$ is said to be removable if the Laurent
    expansion about $z_0$ has no negative terms. In this case, the
    function
    $$
      g(z)
    = \left\{
        \begin{array}{l l}
          f(z), & \quad z \neq z_0 \\
          a_0,  & \quad z = z_0
        \end{array}
    $$
    where $a_0$ is the 0 coefficient of the Laurent series. This is
    because the limit of $f$ exists at $z_0$.

    Sufficiently near a removable singularity, $f$ is bounded,
    explicitly by $|\lim_{z \to z_0} f| + \varepsilon$ for any
    $\varepsilon > 0$.
  }
  \item{
    A singularity $z_0$ of $f$ is said to be a pole of order $m$ if
    $a_{-m} \neq 0$ and $a_{-n} = 0$ for $n > m$. In this case
    $$
      f(z)
    = \frac{g(z)}
           {(z - z_0)^m}
    $$
    where $g$ is holomorphic.

    In this case $\lim_{z \to z_0} |f| = \infty$.
  }
  \item{
    A singularity $z_0$ of $f$ is said to be essential if it is not
    removable or a pole.

    In this case
    $f(D(z_0, r)) = \mathbb{C}$ for any $r > 0$.
  }
\end{enumerate}

\subsection{Finding Laurent series of $\frac{1}{z - z_0}$}
Let
$$
  f(z)
= \frac{1}{z - z_0}
$$
This function is already its own
Laurent series around $z_0$.

When $z_0 \neq 0$, and $\left| \frac{z}{z_0} \right| < 1$,
we have
\begin{align*}
   -\frac{1}{z_0} f(z)
&=  \frac{\frac{1}{z_0}}
         {1 - \frac{z}{z_0}}
 = -\frac{1}{z_0}
    \sum_{n=0}^\infty
      \left(\frac{z}{z_0}\right)^n
\end{align*}
which is a Laurent series around 0.

\subsection{Computing residues}

\subsection{Rouche's theorem}
If $|f(z) - g(z)| < |f(z)|$ on the boundary of a disk
$D$ and $f$, $g$ are analytic on the closed disk, then they have the
same number of zeros within the disk.

\subsection{Open mapping theorem, inverse mapping theorem}
If a holomorphic function is non-constant on every open disk in its
domain, then it is an open mapping. Similarly, if $f^\prime(z_0) \neq
0$, $f$ is locally non-constant and indeed injective, since in this
case $\ord_{z_0} (f - f(z_0)) = 1$ and there is an
$r$ such that for any $w \in D(f(z_0), r)$, $f - w$ has the same
number of zeros as $f - f(z_0)$.

More generally, if $m = \ord_{z_0} (f - f(z_0)) \in \mathbb{N}$, then
$$
f(z) = (\sqrt[m]{a_m} (z - z_0)(1 + h(z)))^m = f_0(z)^m
$$
on some disk $D(z_0, r)$, where $h(z_0) = 0$ and so $f_0^\prime(z_0)
\neq 0$, whence $f_0$ is not constant anywhere on this disk. Therefore
$f_0$ is open, and the image of a disk under the power map is a disk.

If $|f(z_0)|$ is a local maximum for $|f|$, then $f$ is locally
constant at $z_0$. Indeed if $f$ is not locally constant, then
$f(D(z_0, r))$ is open, so $D(f(z_0), s) \subset f(D(z_0, r))$, so
$|f(z_1)| = |f(z_0)| + s > |f(z_0)|$ for some $z_1 \in D(z_0, r)$.

If $f^\prime(z_0) = 0$, then $f^\prime$ is either locally constant or
$z_0$ is an isolated zero of $f^\prime$: it is not true in this case
that $f$ is locally constant, consider $f(z) = z^2 - 1$ at zero.


\section{Contour integration}

\subsection{Half-disk}

\subsection{Half-disk minus half-disk}

\subsection{Taking real parts}

\subsection{Rectangular contours}

\subsection{Trigonometric integrands}

\subsection{Integrals involving branch cuts}



\section{The Schwarz lemma}


\section{M\"obius transformations}

\subsection{Finding the transformation between given circles}

\subsection{Cross ratio}



\section{Riemann mapping theorem}

\subsection{Compact convergence}

\subsection{Normal families}

\subsection{Finding biholomorphisms}

\end{document}
